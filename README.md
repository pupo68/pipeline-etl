# ğŸš€ Pipeline ETL para AnÃ¡lise de Dados de Vendas

## ğŸ¯ Sobre o Projeto

Projeto de **engenharia de dados** que apresenta uma arquitetura completa de pipeline ETL (Extract, Transform, Load) para processamento automatizado de dados de vendas em larga escala. O projeto demonstra competÃªncias avanÃ§adas em arquitetura de dados, processamento distribuÃ­do e implementaÃ§Ã£o de soluÃ§Ãµes de BI em ambiente cloud.

## âœ¨ VisÃ£o Geral da Arquitetura

Este pipeline foi projetado para atender Ã s necessidades de empresas que precisam processar e analisar grandes volumes de dados de vendas de mÃºltiplas fontes, fornecendo uma base sÃ³lida para tomada de decisÃµes baseada em dados.

### ğŸ—ï¸ Componentes Principais

#### **Extract (ExtraÃ§Ã£o)**
- **MÃºltiplas Fontes de Dados**: APIs REST, arquivos CSV/Excel, bancos de dados relacionais
- **Conectores Robustos**: ImplementaÃ§Ã£o de retry logic e tratamento de erros
- **Scheduler Inteligente**: ExecuÃ§Ã£o automÃ¡tica baseada em triggers temporais e eventos
- **ValidaÃ§Ã£o de Dados**: VerificaÃ§Ãµes de integridade na origem

#### **Transform (TransformaÃ§Ã£o)**
- **Limpeza de Dados**: Tratamento de valores nulos, duplicatas e inconsistÃªncias
- **PadronizaÃ§Ã£o**: NormalizaÃ§Ã£o de formatos de data, moeda e categorizaÃ§Ã£o
- **AgregaÃ§Ãµes Complexas**: CÃ¡lculos de mÃ©tricas de vendas, KPIs e indicadores de performance
- **Enriquecimento**: JunÃ§Ã£o com dados externos e criaÃ§Ã£o de features derivadas
- **Qualidade de Dados**: ImplementaÃ§Ã£o de regras de validaÃ§Ã£o e monitoramento

#### **Load (Carga)**
- **Data Warehouse**: PostgreSQL otimizado para consultas analÃ­ticas
- **EstratÃ©gias de Carga**: Incremental, full refresh e merge strategies
- **Particionamento**: OrganizaÃ§Ã£o otimizada por perÃ­odo temporal
- **IndexaÃ§Ã£o Inteligente**: Ãndices estratÃ©gicos para performance de consultas

## ğŸ› ï¸ Stack TecnolÃ³gico

### **Core Technologies**
```
ğŸ Python 3.9+          - Linguagem principal
ğŸ¼ Pandas               - ManipulaÃ§Ã£o e anÃ¡lise de dados
ğŸ—„ï¸  PostgreSQL          - Data Warehouse e OLAP
â˜ï¸  Amazon Web Services  - Infraestrutura cloud
ğŸ“Š Apache Airflow       - OrquestraÃ§Ã£o de workflows
```

### **Ferramentas de Processamento**
```
âš¡ Apache Spark         - Processamento distribuÃ­do
ğŸ”„ SQLAlchemy          - ORM e conexÃµes de banco
ğŸ“ˆ NumPy               - ComputaÃ§Ã£o numÃ©rica
ğŸ” Great Expectations  - ValidaÃ§Ã£o de qualidade de dados
ğŸ“ Loguru              - Sistema de logging avanÃ§ado
```

### **Infraestrutura AWS**
```
ğŸš€ EC2                 - InstÃ¢ncias de processamento
ğŸ’¾ RDS PostgreSQL      - Banco de dados gerenciado
ğŸ“¦ S3                  - Data Lake e armazenamento
ğŸ” IAM                 - Gerenciamento de acesso
ğŸ“Š CloudWatch          - Monitoramento e alertas
âš™ï¸ Lambda              - FunÃ§Ãµes serverless
```

## ğŸ“‹ Funcionalidades Implementadas

### ğŸ”„ **Processamento Automatizado**
- ExtraÃ§Ã£o automÃ¡tica de dados de vendas de mÃºltiplas fontes
- TransformaÃ§Ãµes complexas com validaÃ§Ã£o de regras de negÃ³cio
- Carga incremental otimizada para minimizar tempo de processamento
- Retry automÃ¡tico em caso de falhas com backoff exponencial

### ğŸ“Š **MÃ©tricas e KPIs Calculados**
- **Receita Total**: AgregaÃ§Ãµes por perÃ­odo, regiÃ£o e produto
- **Conversion Rate**: Taxa de conversÃ£o de leads em vendas
- **Customer Lifetime Value (CLV)**: Valor do cliente ao longo do tempo
- **Churn Rate**: Taxa de cancelamento de clientes
- **Sazonalidade**: AnÃ¡lise de padrÃµes temporais de vendas

### ğŸ¯ **Qualidade de Dados**
- ValidaÃ§Ã£o automÃ¡tica de consistÃªncia de dados
- Monitoramento de anomalias em tempo real
- RelatÃ³rios de qualidade de dados
- Alertas automÃ¡ticos para inconsistÃªncias crÃ­ticas

### ğŸ“ˆ **Analytics Ready**
- Modelo dimensional (Star Schema) otimizado para BI
- Views materializadas para consultas de alta performance
- APIs REST para consumo por dashboards
- Conectores para ferramentas de visualizaÃ§Ã£o (Tableau, Power BI)

## ğŸ›ï¸ Arquitetura de Dados

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SOURCES       â”‚    â”‚   PROCESSING     â”‚    â”‚   DESTINATION   â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ CRM APIs      â”‚â”€â”€â”€â–¶â”‚  ETL Pipeline    â”‚â”€â”€â”€â–¶â”‚ PostgreSQL DW   â”‚
â”‚ â€¢ CSV Files     â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ E-commerce    â”‚    â”‚ â€¢ Data Cleaning  â”‚    â”‚ â€¢ Fact Tables   â”‚
â”‚ â€¢ ERP Systems   â”‚    â”‚ â€¢ Transformationsâ”‚    â”‚ â€¢ Dimension Tblsâ”‚
â”‚ â€¢ Web Analytics â”‚    â”‚ â€¢ Aggregations   â”‚    â”‚ â€¢ Materialized  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â€¢ Validations    â”‚    â”‚   Views         â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   ORCHESTRATION  â”‚
                       â”‚                  â”‚
                       â”‚ â€¢ Apache Airflow â”‚
                       â”‚ â€¢ Scheduling     â”‚
                       â”‚ â€¢ Monitoring     â”‚
                       â”‚ â€¢ Error Handling â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Schema do Data Warehouse

### **Fact Table: sales_fact**
```sql
- sale_id (PK)
- date_key (FK)
- customer_key (FK)
- product_key (FK)
- sales_amount
- quantity
- discount_amount
- profit_margin
```

### **Dimension Tables**
```sql
â€¢ dim_date: DimensÃ£o temporal completa
â€¢ dim_customer: Dados de clientes e segmentaÃ§Ã£o
â€¢ dim_product: CatÃ¡logo de produtos e categorias
â€¢ dim_geography: Hierarquia geogrÃ¡fica
â€¢ dim_sales_channel: Canais de venda
```

## ğŸš€ ImplementaÃ§Ã£o e Deploy

### **PrÃ©-requisitos**
```bash
â€¢ Python 3.9+
â€¢ Docker & Docker Compose
â€¢ AWS CLI configurado
â€¢ PostgreSQL 13+
â€¢ Apache Airflow 2.5+
```

### **ConfiguraÃ§Ã£o Local (Desenvolvimento)**
```bash
# 1. Clone do repositÃ³rio
git clone https://github.com/pupo68/pipeline-etl.git
cd pipeline-etl

# 2. Ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# 3. InstalaÃ§Ã£o de dependÃªncias
pip install -r requirements.txt

# 4. ConfiguraÃ§Ã£o do banco
cp .env.example .env
# Editar .env com suas credenciais

# 5. InicializaÃ§Ã£o do banco
python setup_database.py

# 6. ExecuÃ§Ã£o do pipeline
python main_pipeline.py
```

### **Deploy na AWS**
```bash
# 1. ConfiguraÃ§Ã£o do Terraform
cd terraform/
terraform init
terraform plan
terraform apply

# 2. Deploy do Airflow
kubectl apply -f k8s/

# 3. ConfiguraÃ§Ã£o de DAGs
aws s3 cp dags/ s3://airflow-dags-bucket/ --recursive
```

## ğŸ“ˆ Casos de Uso PrÃ¡ticos

### ğŸ¯ **Business Intelligence**
- Dashboards executivos com KPIs em tempo real
- AnÃ¡lise de performance de vendedores e territÃ³rios
- Forecasting e previsÃ£o de demanda
- AnÃ¡lise de rentabilidade por produto/cliente

### ğŸ“Š **Analytics AvanÃ§ado**
- SegmentaÃ§Ã£o de clientes (RFM Analysis)
- Market Basket Analysis
- AnÃ¡lise de cohort e retenÃ§Ã£o
- DetecÃ§Ã£o de anomalias em vendas

### ğŸ” **Monitoramento Operacional**
- SLAs de processamento de dados
- Alertas de qualidade de dados
- Monitoramento de performance do pipeline
- Auditoria e rastreabilidade de dados

## ğŸŒŸ Diferenciais para PortfÃ³lio/CurrÃ­culo

âœ… **Arquitetura Enterprise**: Demonstra capacidade de projetar soluÃ§Ãµes escalÃ¡veis e robustas

âœ… **Cloud Engineering**: ExperiÃªncia com AWS e infraestrutura como cÃ³digo

âœ… **Data Engineering**: Pipeline completo de dados com foco em qualidade e performance

âœ… **DevOps & MLOps**: ImplementaÃ§Ã£o de CI/CD para pipelines de dados

âœ… **Business Acumen**: Entendimento de mÃ©tricas de negÃ³cio e KPIs relevantes

âœ… **Escalabilidade**: Arquitetura preparada para crescimento e alta disponibilidade

âœ… **Monitoring & Observability**: ImplementaÃ§Ã£o de monitoramento proativo

âœ… **Documentation**: DocumentaÃ§Ã£o tÃ©cnica profissional e abrangente

## ğŸ”§ Roadmap de Melhorias

### **Fase 1: OtimizaÃ§Ã£o**
- [ ] ImplementaÃ§Ã£o de cache distribuÃ­do (Redis)
- [ ] OtimizaÃ§Ã£o de queries com particionamento avanÃ§ado
- [ ] CompressÃ£o de dados histÃ³ricos

### **Fase 2: ML Integration**
- [ ] Modelos de Machine Learning para forecasting
- [ ] DetecÃ§Ã£o automÃ¡tica de anomalias
- [ ] RecomendaÃ§Ã£o de produtos baseada em dados

### **Fase 3: Real-time Processing**
- [ ] Streaming com Apache Kafka
- [ ] Processamento em tempo real com Apache Flink
- [ ] Dashboard em tempo real

### **Fase 4: Advanced Analytics**
- [ ] Data Lake com Delta Lake
- [ ] ImplementaÃ§Ã£o de Data Mesh
- [ ] Self-service analytics

## ğŸ“Š MÃ©tricas de Performance

| MÃ©trica | Valor |
|---------|-------|
| **Throughput** | 1M+ registros/hora |
| **LatÃªncia** | < 5 minutos (end-to-end) |
| **Disponibilidade** | 99.9% SLA |
| **Qualidade de Dados** | 99.95% accuracy |
| **Recovery Time** | < 15 minutos |

## ğŸ›¡ï¸ SeguranÃ§a e Compliance

- **Criptografia**: Dados em trÃ¢nsito e em repouso
- **Access Control**: RBAC implementado
- **Audit Trail**: Log completo de todas as operaÃ§Ãµes
- **Data Lineage**: Rastreabilidade completa dos dados
- **LGPD/GDPR Ready**: Estrutura preparada para compliance

## ğŸ“š DocumentaÃ§Ã£o TÃ©cnica

- **[Architecture Decision Records (ADRs)](docs/adr/)**
- **[API Documentation](docs/api/)**
- **[Deployment Guide](docs/deployment/)**
- **[Monitoring Runbook](docs/monitoring/)**
- **[Disaster Recovery Plan](docs/dr/)**

## ğŸ¤ ContribuiÃ§Ãµes

Este projeto segue as melhores prÃ¡ticas de engenharia de software:

- **Code Review**: Processo estruturado de revisÃ£o
- **Testing**: Cobertura de testes > 80%
- **CI/CD**: Pipeline automatizado de deploy
- **Documentation**: DocumentaÃ§Ã£o sempre atualizada

## ğŸ“‹ LicenÃ§a

Projeto desenvolvido para fins educacionais e de portfÃ³lio profissional.

## ğŸ‘¤ Autor

**Gustavo Pupo**
- ğŸ”— GitHub: [@pupo68](https://github.com/pupo68)
- ğŸ“§ Email: gustavopupo49@gmail.com
- ğŸ’¼ LinkedIn: [Conectar](https://linkedin.com/in/gustavo-pupo)

---

â­ **Se este projeto demonstrou valor, considere dar uma estrela!**

**ğŸš€ Desenvolvido com expertise em Data Engineering e Cloud Architecture**
